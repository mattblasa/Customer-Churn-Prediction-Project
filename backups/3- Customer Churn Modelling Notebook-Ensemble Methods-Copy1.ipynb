{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Final Project Submission\n",
    "\n",
    "Please fill out:\n",
    "* Student name: Seyma Tas\n",
    "* Student pace: full time\n",
    "* Scheduled project review date/time: \n",
    "* Instructor name: Amber Yandow\n",
    "* Blog post URL:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-30T02:59:14.210353Z",
     "start_time": "2020-05-30T02:59:14.198693Z"
    }
   },
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "sns.set_style('darkgrid', {'axes.facecolor': '0.9'})\n",
    "\n",
    "from sklearn.preprocessing import LabelEncoder, OneHotEncoder, MinMaxScaler, StandardScaler\n",
    "from sklearn.model_selection import train_test_split, cross_val_score, GridSearchCV, ParameterGrid\n",
    "from sklearn.linear_model import LogisticRegression, SGDClassifier\n",
    "from imblearn.over_sampling import SMOTE, ADASYN\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier, AdaBoostClassifier, GradientBoostingClassifier, BaggingClassifier\n",
    "from sklearn.metrics import recall_score, f1_score, fbeta_score, r2_score, roc_auc_score, roc_curve, auc, cohen_kappa_score\n",
    "from sklearn.metrics import classification_report, confusion_matrix, accuracy_score, precision_score\n",
    "from sklearn.metrics import make_scorer\n",
    "from sklearn.pipeline import Pipeline\n",
    "import xgboost as xgb\n",
    "# from sklearn.metrics import plot_confusion_matrix\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-30T02:59:17.202523Z",
     "start_time": "2020-05-30T02:59:17.185987Z"
    }
   },
   "outputs": [],
   "source": [
    "df = pd.read_csv('TelcoCustomerChurnData_cleaned_ohe.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Splitting the data into test and train sets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-30T02:59:19.501235Z",
     "start_time": "2020-05-30T02:59:19.496627Z"
    }
   },
   "outputs": [],
   "source": [
    "X = df.drop(['Churn'], axis=1)\n",
    "y = df['Churn']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-30T02:59:20.024889Z",
     "start_time": "2020-05-30T02:59:20.018046Z"
    }
   },
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-30T02:59:20.827203Z",
     "start_time": "2020-05-30T02:59:20.816822Z"
    }
   },
   "outputs": [],
   "source": [
    "scaler = StandardScaler()\n",
    "scaled_x_train = scaler.fit_transform(X_train)\n",
    "scaled_X_test = scaler.transform(X_test)\n",
    "scaled_X_train = pd.DataFrame(scaled_x_train, columns=X_train.columns)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Functions to evaluate the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-30T02:59:23.049857Z",
     "start_time": "2020-05-30T02:59:23.040023Z"
    },
    "code_folding": [
     0
    ]
   },
   "outputs": [],
   "source": [
    "def roc_curve_and_auc(clf, X_train, X_test, y_train, y_test):\n",
    "\n",
    "    # Calculate the probability scores of each point in the training set\n",
    "    y_train_score = clf.fit(X_train, y_train).decision_function(X_train)\n",
    "\n",
    "    # Calculate the fpr, tpr, and thresholds for the training set\n",
    "    train_fpr, train_tpr, thresholds = roc_curve(y_train, y_train_score)\n",
    "\n",
    "    # Calculate the probability scores of each point in the test set\n",
    "    y_test_score = clf.decision_function(X_test)\n",
    "\n",
    "    # Calculate the fpr, tpr, and thresholds for the test set\n",
    "    test_fpr, test_tpr, test_thresholds = roc_curve(y_test, y_test_score)\n",
    "\n",
    "    # ROC curve for training set\n",
    "    plt.figure(figsize=(10, 8))\n",
    "    lw = 2\n",
    "    plt.plot(train_fpr, train_tpr, color='darkorange',\n",
    "             lw=lw, label='Train ROC curve')\n",
    "    plt.plot(test_fpr, test_tpr, color='blue',\n",
    "             lw=lw, label='Test ROC curve')\n",
    "    plt.plot([0, 1], [0, 1], color='navy', lw=lw, linestyle='--')\n",
    "    plt.xlim([0.0, 1.0])\n",
    "    plt.ylim([0.0, 1.05])\n",
    "    plt.yticks([i/20.0 for i in range(21)])\n",
    "    plt.xticks([i/20.0 for i in range(21)])\n",
    "    plt.xlabel('False Positive Rate')\n",
    "    plt.ylabel('True Positive Rate')\n",
    "    plt.title('Receiver operating characteristic (ROC) Curve for Training and Testing Sets')\n",
    "    plt.legend(loc='lower right')\n",
    "    plt.show()\n",
    "    # Print the area under the roc curve\n",
    "    print('Training AUC: {}'.format(round(auc(train_fpr, train_tpr), 5)))\n",
    "    print('Testing AUC: {}'.format(round(auc(test_fpr, test_tpr), 5)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-30T02:59:23.543131Z",
     "start_time": "2020-05-30T02:59:23.537848Z"
    },
    "code_folding": []
   },
   "outputs": [],
   "source": [
    "def plot_feature_importances(model):\n",
    "    n_features = X_train.shape[1]\n",
    "    plt.figure(figsize=(8,8))\n",
    "    plt.barh(range(n_features), model.feature_importances_, align='center') \n",
    "    plt.yticks(np.arange(n_features), X_train.columns.values) \n",
    "    plt.xlabel('Feature importance')\n",
    "    plt.ylabel('Feature')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-30T02:59:24.046746Z",
     "start_time": "2020-05-30T02:59:24.042826Z"
    }
   },
   "outputs": [],
   "source": [
    "# # Plot features importances metric evaluation fonksiyonuna bunu ekleyecegim\n",
    "# imp = pd.Series(data=clf.feature_importances_, index=x.columns).sort_values(ascending=False)\n",
    "# plt.figure(figsize=(10,12))\n",
    "# plt.title(\"Feature importance\")\n",
    "# ax = sns.barplot(y=imp.index, x=imp.values, palette=\"Blues_d\", orient='h')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-30T02:59:24.479613Z",
     "start_time": "2020-05-30T02:59:24.472064Z"
    },
    "code_folding": []
   },
   "outputs": [],
   "source": [
    "def model_evaluation(X_train, X_test, y_train, y_test, y_pred_train, y_pred_test):\n",
    "\n",
    "    print('MODEL EVALUATION METRICS:\\n',\n",
    "          '-----------------------------------------------------')\n",
    "    print('Confusion Matrix for train & test set: \\n')\n",
    "    print(confusion_matrix(y_train, y_pred_train),'\\n')\n",
    "    \n",
    "    print(confusion_matrix(y_test, y_pred_test))\n",
    "    \n",
    "    print('-----------------------------------------------------')\n",
    "    print('\\nClassification Report for train & test set\\n',\n",
    "          '\\nTrain set\\n',\n",
    "          classification_report(y_train, y_pred_train),\n",
    "          '\\n\\nTest set\\n',\n",
    "          classification_report(y_test, y_pred_test))\n",
    "    \n",
    "#     print('\\nRecall for train & test set:\\n',\n",
    "#           round(recall_score(y_train, y_pred_train), 4),\n",
    "#           round(recall_score(y_test, y_pred_test), 4))\n",
    "       \n",
    "#     print('Precision for train & test set:\\n', \n",
    "#           round(precision_score(y_train, y_pred_train), 4),\n",
    "#           round(precision_score(y_test, y_pred_test), 4))\n",
    "\n",
    "#     print('f1 score for train & test set:\\n', \n",
    "#           round(f1_score(y_train, y_pred_train), 4),\n",
    "#           round(f1_score(y_test, y_pred_test), 4))\n",
    "\n",
    "#     print('Accuracy for train and test set:\\n ',\n",
    "#           round(accuracy_score(y_train, y_pred_train), 4),\n",
    "#           round(accuracy_score(y_test, y_pred_test), 4))\n",
    "    print('-----------------------------------------------------\\n')\n",
    "    print(\"Cohen's Kappa for train and test set:\\n \",\n",
    "            round(cohen_kappa_score(y_train, y_pred_train), 4),\n",
    "            round(cohen_kappa_score(y_test, y_pred_test), 4))\n",
    "\n",
    "    print (\"f2 score for train and test set: \\n \",\n",
    "           round(fbeta_score(y_train, y_pred_train)), \n",
    "           round(fbeta_score(y_test, y_pred_test)))\n",
    "    \n",
    "    print ('roc auc score for train and test set:\\n ', \n",
    "           round(roc_auc_score(y_train, y_pred_train),4),\n",
    "           round(roc_auc_score(y_test, y_pred_test),4) )\n",
    "    \n",
    "    print('Mean Cross Validation Score:\\n', round(cross_val_score(clf, X, y, cv=5).mean(), 4))   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-29T23:54:34.654870Z",
     "start_time": "2020-05-29T23:54:34.644387Z"
    }
   },
   "outputs": [],
   "source": [
    "def confusion_matrix_df(y_test, y_pred_test):\n",
    "    confusion_mat = confusion_matrix(y_test, y_pred_test, labels=[0, 1])\n",
    "    _row = confusion_mat.sum(axis=0)\n",
    "    _col = [np.nan] + list(confusion_mat.sum(axis=1)) + [sum(_row)]\n",
    "    con_df = pd.DataFrame({})\n",
    "    con_df[\"Predicted\"] = [\"Actual\"] + [\"No Churn\", \"Churn\"] + [\"All\"]\n",
    "    for label, idx in {\"No Churn\": 0, \"Churn\": 1}.items():\n",
    "        temp = [np.nan] + list(confusion_mat[:, idx]) + [_row[idx]]\n",
    "        con_df[label] = temp\n",
    "\n",
    "    con_df[\"All\"] = _col\n",
    "    return con_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Bagging Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-29T05:18:34.824511Z",
     "start_time": "2020-05-29T05:18:34.821099Z"
    }
   },
   "outputs": [],
   "source": [
    "clf = BaggingClassifier(DecisionTreeClassifier(criterion='gini', max_depth=5), \n",
    "                                 n_estimators=20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-29T05:18:37.082522Z",
     "start_time": "2020-05-29T05:18:36.875839Z"
    }
   },
   "outputs": [],
   "source": [
    "clf.fit(X_train, y_train)\n",
    "y_pred_train = clf.predict(X_train)\n",
    "y_pred_test = clf.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-29T05:18:38.782646Z",
     "start_time": "2020-05-29T05:18:37.771864Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MODEL EVALUATION METRICS:\n",
      " -----------------------------------------------------\n",
      "Confusion Matrix for train & test set: \n",
      "\n",
      "[[3537  326]\n",
      " [ 664  747]] \n",
      "\n",
      "[[1176  124]\n",
      " [ 239  219]]\n",
      "-----------------------------------------------------\n",
      "\n",
      "Classification Report for train & test set\n",
      " \n",
      "Train set\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.84      0.92      0.88      3863\n",
      "           1       0.70      0.53      0.60      1411\n",
      "\n",
      "    accuracy                           0.81      5274\n",
      "   macro avg       0.77      0.72      0.74      5274\n",
      "weighted avg       0.80      0.81      0.80      5274\n",
      " \n",
      "\n",
      "Test set\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.83      0.90      0.87      1300\n",
      "           1       0.64      0.48      0.55       458\n",
      "\n",
      "    accuracy                           0.79      1758\n",
      "   macro avg       0.73      0.69      0.71      1758\n",
      "weighted avg       0.78      0.79      0.78      1758\n",
      "\n",
      "-----------------------------------------------------\n",
      "\n",
      "Cohen's Kappa for train and test set:\n",
      "  0.4816 0.4167\n",
      "roc auc score for train and test set:\n",
      "  0.7225 0.6914\n",
      "Mean Cross Validation Score:\n",
      " 0.7979\n"
     ]
    }
   ],
   "source": [
    "model_evaluation(X_train, X_test, y_train, y_test, y_pred_train, y_pred_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-29T05:19:06.244135Z",
     "start_time": "2020-05-29T05:19:06.241610Z"
    }
   },
   "outputs": [],
   "source": [
    "# roc_curve_and_auc(clf, X_train, X_test, y_train, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Xgboost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-30T03:58:18.907842Z",
     "start_time": "2020-05-30T03:58:18.025357Z"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "feature_names mismatch: ['f0', 'f1', 'f2', 'f3', 'f4', 'f5', 'f6', 'f7', 'f8', 'f9', 'f10', 'f11', 'f12', 'f13', 'f14', 'f15', 'f16', 'f17', 'f18', 'f19', 'f20', 'f21', 'f22', 'f23', 'f24', 'f25', 'f26', 'f27', 'f28', 'f29'] ['f0', 'f1', 'f2', 'f3', 'f4', 'f5', 'f6', 'f7', 'f8', 'f9', 'f10', 'f11', 'f12', 'f13', 'f14', 'f15', 'f16', 'f17', 'f18', 'f19', 'f20', 'f21', 'f22', 'f23']\nexpected f25, f24, f29, f27, f28, f26 in input data",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-64-5c535aa48bd7>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0mclf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mscaled_X_train_smoted\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train_smoted\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[0my_pred_train\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mclf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mscaled_X_train_smoted\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 11\u001b[0;31m \u001b[0my_pred_test\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mclf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mscaled_X_test\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/opt/anaconda3/lib/python3.7/site-packages/xgboost/sklearn.py\u001b[0m in \u001b[0;36mpredict\u001b[0;34m(self, data, output_margin, ntree_limit, validate_features)\u001b[0m\n\u001b[1;32m    789\u001b[0m                                                  \u001b[0moutput_margin\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0moutput_margin\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    790\u001b[0m                                                  \u001b[0mntree_limit\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mntree_limit\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 791\u001b[0;31m                                                  validate_features=validate_features)\n\u001b[0m\u001b[1;32m    792\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0moutput_margin\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    793\u001b[0m             \u001b[0;31m# If output_margin is active, simply return the scores\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/lib/python3.7/site-packages/xgboost/core.py\u001b[0m in \u001b[0;36mpredict\u001b[0;34m(self, data, output_margin, ntree_limit, pred_leaf, pred_contribs, approx_contribs, pred_interactions, validate_features)\u001b[0m\n\u001b[1;32m   1282\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1283\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mvalidate_features\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1284\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_validate_features\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1285\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1286\u001b[0m         \u001b[0mlength\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mc_bst_ulong\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/lib/python3.7/site-packages/xgboost/core.py\u001b[0m in \u001b[0;36m_validate_features\u001b[0;34m(self, data)\u001b[0m\n\u001b[1;32m   1688\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1689\u001b[0m                 raise ValueError(msg.format(self.feature_names,\n\u001b[0;32m-> 1690\u001b[0;31m                                             data.feature_names))\n\u001b[0m\u001b[1;32m   1691\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1692\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mget_split_value_histogram\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeature\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfmap\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m''\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbins\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mas_pandas\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: feature_names mismatch: ['f0', 'f1', 'f2', 'f3', 'f4', 'f5', 'f6', 'f7', 'f8', 'f9', 'f10', 'f11', 'f12', 'f13', 'f14', 'f15', 'f16', 'f17', 'f18', 'f19', 'f20', 'f21', 'f22', 'f23', 'f24', 'f25', 'f26', 'f27', 'f28', 'f29'] ['f0', 'f1', 'f2', 'f3', 'f4', 'f5', 'f6', 'f7', 'f8', 'f9', 'f10', 'f11', 'f12', 'f13', 'f14', 'f15', 'f16', 'f17', 'f18', 'f19', 'f20', 'f21', 'f22', 'f23']\nexpected f25, f24, f29, f27, f28, f26 in input data"
     ]
    }
   ],
   "source": [
    "clf = xgb.XGBClassifier(objective= 'binary:logistic',\n",
    "    nthread=4,\n",
    "    scale_pos_weight=3,\n",
    "    seed=42,\n",
    "    max_depth=3,\n",
    "    n_estimators=140,\n",
    "    learning_rate=0.05,                     \n",
    "                       )\n",
    "clf.fit(scaled_X_train_smoted, y_train_smoted)\n",
    "y_pred_train = clf.predict(scaled_X_train_smoted)\n",
    "y_pred_test = clf.predict(scaled_X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-30T03:58:19.951220Z",
     "start_time": "2020-05-30T03:58:19.896523Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MODEL EVALUATION METRICS:\n",
      " -----------------------------------------------------\n",
      "Confusion Matrix for train & test set: \n",
      "\n",
      "[[2348 1515]\n",
      " [ 121 3742]] \n",
      "\n",
      "[[1019  281]\n",
      " [ 172  286]]\n",
      "-----------------------------------------------------\n",
      "\n",
      "Classification Report for train & test set\n",
      " \n",
      "Train set\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.95      0.61      0.74      3863\n",
      "           1       0.71      0.97      0.82      3863\n",
      "\n",
      "    accuracy                           0.79      7726\n",
      "   macro avg       0.83      0.79      0.78      7726\n",
      "weighted avg       0.83      0.79      0.78      7726\n",
      " \n",
      "\n",
      "Test set\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.86      0.78      0.82      1300\n",
      "           1       0.50      0.62      0.56       458\n",
      "\n",
      "    accuracy                           0.74      1758\n",
      "   macro avg       0.68      0.70      0.69      1758\n",
      "weighted avg       0.76      0.74      0.75      1758\n",
      "\n",
      "-----------------------------------------------------\n",
      "\n",
      "Cohen's Kappa for train and test set:\n",
      "  0.5765 0.3791\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "fbeta_score() missing 1 required positional argument: 'beta'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-65-a3b7b4d4c142>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mmodel_evaluation\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mscaled_X_train_smoted\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mscaled_X_test\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train_smoted\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_test\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_pred_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_pred_test\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-63-b3a1103e67e8>\u001b[0m in \u001b[0;36mmodel_evaluation\u001b[0;34m(X_train, X_test, y_train, y_test, y_pred_train, y_pred_test)\u001b[0m\n\u001b[1;32m     36\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     37\u001b[0m     print (\"f2 score for train and test set: \\n \",\n\u001b[0;32m---> 38\u001b[0;31m            \u001b[0mround\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfbeta_score\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_pred_train\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     39\u001b[0m            round(fbeta_score(y_test, y_pred_test)))\n\u001b[1;32m     40\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mTypeError\u001b[0m: fbeta_score() missing 1 required positional argument: 'beta'"
     ]
    }
   ],
   "source": [
    "model_evaluation(scaled_X_train_smoted, scaled_X_test, y_train_smoted, y_test, y_pred_train, y_pred_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# roc_curve_and_auc(clf, X_train, X_test, y_train, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf.feature_importances_.round(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_feature_importances(clf)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Gridsearch XGBoost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-29T11:56:47.535489Z",
     "start_time": "2020-05-29T11:56:47.532612Z"
    }
   },
   "outputs": [],
   "source": [
    "estimator = xgb.XGBClassifier(\n",
    "    objective= 'binary:logistic',\n",
    "    nthread=4,\n",
    "    scale_pos_weight=3,\n",
    "    seed=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-29T05:57:08.512683Z",
     "start_time": "2020-05-29T05:57:08.509060Z"
    }
   },
   "outputs": [],
   "source": [
    "grid = {\n",
    "    'max_depth': range (2, 10, 1),\n",
    "    'n_estimators': range(60, 220, 40),\n",
    "    'learning_rate': [0.1, 0.01, 0.05, ]\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-29T11:56:41.424308Z",
     "start_time": "2020-05-29T11:56:41.420772Z"
    }
   },
   "outputs": [],
   "source": [
    "clf = GridSearchCV(\n",
    "    estimator=estimator,\n",
    "    param_grid=grid,\n",
    "    scoring = 'accuracy',\n",
    "    n_jobs = 10,\n",
    "    cv = 10,\n",
    "    verbose=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-29T06:07:38.266411Z",
     "start_time": "2020-05-29T05:57:38.155092Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 10 folds for each of 96 candidates, totalling 960 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=10)]: Using backend LokyBackend with 10 concurrent workers.\n",
      "[Parallel(n_jobs=10)]: Done  30 tasks      | elapsed:   10.8s\n",
      "[Parallel(n_jobs=10)]: Done 180 tasks      | elapsed:  1.3min\n",
      "[Parallel(n_jobs=10)]: Done 430 tasks      | elapsed:  3.9min\n",
      "[Parallel(n_jobs=10)]: Done 780 tasks      | elapsed:  7.7min\n",
      "[Parallel(n_jobs=10)]: Done 960 out of 960 | elapsed: 10.0min finished\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=10, error_score='raise-deprecating',\n",
       "             estimator=XGBClassifier(base_score=0.5, booster='gbtree',\n",
       "                                     colsample_bylevel=1, colsample_bynode=1,\n",
       "                                     colsample_bytree=1, gamma=0,\n",
       "                                     learning_rate=0.1, max_delta_step=0,\n",
       "                                     max_depth=3, min_child_weight=1,\n",
       "                                     missing=None, n_estimators=100, n_jobs=1,\n",
       "                                     nthread=4, objective='binary:logistic',\n",
       "                                     random_state=0, reg_alpha=0, reg_lambda=1,\n",
       "                                     scale_pos_weight=3, seed=42, silent=None,\n",
       "                                     subsample=1, verbosity=1),\n",
       "             iid='warn', n_jobs=10,\n",
       "             param_grid={'learning_rate': [0.1, 0.01, 0.05],\n",
       "                         'max_depth': range(2, 10),\n",
       "                         'n_estimators': range(60, 220, 40)},\n",
       "             pre_dispatch='2*n_jobs', refit=True, return_train_score=False,\n",
       "             scoring='roc_auc', verbose=True)"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-29T11:49:57.603229Z",
     "start_time": "2020-05-29T11:49:57.598984Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'learning_rate': 0.05, 'max_depth': 3, 'n_estimators': 140}"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf.best_params_\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# scoring=accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-29T11:58:38.420928Z",
     "start_time": "2020-05-29T11:58:38.418009Z"
    }
   },
   "outputs": [],
   "source": [
    "estimator = xgb.XGBClassifier(\n",
    "    objective= 'binary:logistic',\n",
    "    nthread=4,\n",
    "    scale_pos_weight=3,\n",
    "    seed=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-29T11:58:39.084290Z",
     "start_time": "2020-05-29T11:58:39.081109Z"
    }
   },
   "outputs": [],
   "source": [
    "grid = {\n",
    "    'max_depth': range (2, 10, 1),\n",
    "    'n_estimators': range(60, 220, 40),\n",
    "    'learning_rate': [0.1, 0.01, 0.05, ]\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-29T11:58:41.668850Z",
     "start_time": "2020-05-29T11:58:41.665605Z"
    }
   },
   "outputs": [],
   "source": [
    "clf = GridSearchCV(\n",
    "    estimator=estimator,\n",
    "    param_grid=grid,\n",
    "    scoring = 'accuracy',\n",
    "    n_jobs = 10,\n",
    "    cv = 10,\n",
    "    verbose=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-29T12:31:13.064000Z",
     "start_time": "2020-05-29T11:58:42.640946Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 10 folds for each of 96 candidates, totalling 960 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=10)]: Using backend LokyBackend with 10 concurrent workers.\n",
      "[Parallel(n_jobs=10)]: Done  30 tasks      | elapsed:    8.8s\n",
      "[Parallel(n_jobs=10)]: Done 180 tasks      | elapsed:  1.1min\n",
      "[Parallel(n_jobs=10)]: Done 430 tasks      | elapsed:  9.9min\n",
      "[Parallel(n_jobs=10)]: Done 780 tasks      | elapsed: 23.4min\n",
      "[Parallel(n_jobs=10)]: Done 960 out of 960 | elapsed: 32.0min finished\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=10, error_score='raise-deprecating',\n",
       "             estimator=XGBClassifier(base_score=0.5, booster='gbtree',\n",
       "                                     colsample_bylevel=1, colsample_bynode=1,\n",
       "                                     colsample_bytree=1, gamma=0,\n",
       "                                     learning_rate=0.1, max_delta_step=0,\n",
       "                                     max_depth=3, min_child_weight=1,\n",
       "                                     missing=None, n_estimators=100, n_jobs=1,\n",
       "                                     nthread=4, objective='binary:logistic',\n",
       "                                     random_state=0, reg_alpha=0, reg_lambda=1,\n",
       "                                     scale_pos_weight=3, seed=42, silent=None,\n",
       "                                     subsample=1, verbosity=1),\n",
       "             iid='warn', n_jobs=10,\n",
       "             param_grid={'learning_rate': [0.1, 0.01, 0.05],\n",
       "                         'max_depth': range(2, 10),\n",
       "                         'n_estimators': range(60, 220, 40)},\n",
       "             pre_dispatch='2*n_jobs', refit=True, return_train_score=False,\n",
       "             scoring='accuracy', verbose=True)"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-29T13:02:07.029496Z",
     "start_time": "2020-05-29T13:02:07.023643Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'learning_rate': 0.1, 'max_depth': 9, 'n_estimators': 180}"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf.best_params_\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-29T13:03:11.219742Z",
     "start_time": "2020-05-29T13:03:11.121323Z"
    }
   },
   "outputs": [],
   "source": [
    "y_pred_train = clf.predict(X_train)\n",
    "y_pred_test = clf.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-29T16:26:57.995795Z",
     "start_time": "2020-05-29T13:03:11.890295Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MODEL EVALUATION METRICS:\n",
      " -----------------------------------------------------\n",
      "Confusion Matrix for train & test set: \n",
      "\n",
      "[[3658  205]\n",
      " [   2 1409]] \n",
      "\n",
      "[[1019  281]\n",
      " [ 172  286]]\n",
      "-----------------------------------------------------\n",
      "\n",
      "Classification Report for train & test set\n",
      " \n",
      "Train set\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.95      0.97      3863\n",
      "           1       0.87      1.00      0.93      1411\n",
      "\n",
      "    accuracy                           0.96      5274\n",
      "   macro avg       0.94      0.97      0.95      5274\n",
      "weighted avg       0.97      0.96      0.96      5274\n",
      " \n",
      "\n",
      "Test set\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.86      0.78      0.82      1300\n",
      "           1       0.50      0.62      0.56       458\n",
      "\n",
      "    accuracy                           0.74      1758\n",
      "   macro avg       0.68      0.70      0.69      1758\n",
      "weighted avg       0.76      0.74      0.75      1758\n",
      "\n",
      "-----------------------------------------------------\n",
      "\n",
      "Cohen's Kappa for train and test set:\n",
      "  0.9042 0.3791\n",
      "roc auc score for train and test set:\n",
      "  0.9728 0.7042\n",
      "Fitting 10 folds for each of 96 candidates, totalling 960 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=10)]: Using backend LokyBackend with 10 concurrent workers.\n",
      "[Parallel(n_jobs=10)]: Done  30 tasks      | elapsed:   26.5s\n",
      "[Parallel(n_jobs=10)]: Done 180 tasks      | elapsed:  4.0min\n",
      "[Parallel(n_jobs=10)]: Done 430 tasks      | elapsed: 12.8min\n",
      "[Parallel(n_jobs=10)]: Done 780 tasks      | elapsed: 26.2min\n",
      "[Parallel(n_jobs=10)]: Done 960 out of 960 | elapsed: 35.6min finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 10 folds for each of 96 candidates, totalling 960 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=10)]: Using backend LokyBackend with 10 concurrent workers.\n",
      "[Parallel(n_jobs=10)]: Done  30 tasks      | elapsed:   20.7s\n",
      "[Parallel(n_jobs=10)]: Done 180 tasks      | elapsed:  4.4min\n",
      "[Parallel(n_jobs=10)]: Done 430 tasks      | elapsed: 21.5min\n",
      "[Parallel(n_jobs=10)]: Done 780 tasks      | elapsed: 36.3min\n",
      "[Parallel(n_jobs=10)]: Done 960 out of 960 | elapsed: 45.7min finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 10 folds for each of 96 candidates, totalling 960 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=10)]: Using backend LokyBackend with 10 concurrent workers.\n",
      "[Parallel(n_jobs=10)]: Done  30 tasks      | elapsed:   22.5s\n",
      "[Parallel(n_jobs=10)]: Done 180 tasks      | elapsed:  4.2min\n",
      "[Parallel(n_jobs=10)]: Done 430 tasks      | elapsed: 13.7min\n",
      "[Parallel(n_jobs=10)]: Done 780 tasks      | elapsed: 28.0min\n",
      "[Parallel(n_jobs=10)]: Done 960 out of 960 | elapsed: 39.1min finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 10 folds for each of 96 candidates, totalling 960 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=10)]: Using backend LokyBackend with 10 concurrent workers.\n",
      "[Parallel(n_jobs=10)]: Done  30 tasks      | elapsed:   25.3s\n",
      "[Parallel(n_jobs=10)]: Done 180 tasks      | elapsed:  5.2min\n",
      "[Parallel(n_jobs=10)]: Done 430 tasks      | elapsed: 17.7min\n",
      "[Parallel(n_jobs=10)]: Done 780 tasks      | elapsed: 36.8min\n",
      "[Parallel(n_jobs=10)]: Done 960 out of 960 | elapsed: 47.9min finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 10 folds for each of 96 candidates, totalling 960 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=10)]: Using backend LokyBackend with 10 concurrent workers.\n",
      "[Parallel(n_jobs=10)]: Done  30 tasks      | elapsed:   23.8s\n",
      "[Parallel(n_jobs=10)]: Done 180 tasks      | elapsed:  4.7min\n",
      "[Parallel(n_jobs=10)]: Done 430 tasks      | elapsed: 15.6min\n",
      "[Parallel(n_jobs=10)]: Done 780 tasks      | elapsed: 29.4min\n",
      "[Parallel(n_jobs=10)]: Done 960 out of 960 | elapsed: 31.4min finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean Cross Validation Score:\n",
      " 0.7625\n"
     ]
    }
   ],
   "source": [
    "model_evaluation(X_train, X_test, y_train, y_test, y_pred_train, y_pred_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Gradient Boosting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf = GradientBoostingClassifier()\n",
    "clf.fit(X_train, y_train)\n",
    "y_pred_train = clf.predict(X_train)\n",
    "y_pred_test = clf.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_evaluation(X_train, X_test, y_train, y_test, y_pred_train, y_pred_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "roc_curve_and_auc(clf, X_train, X_test, y_train, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf.feature_importances_.round(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_feature_importances(clf)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Adaboost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf = AdaBoostClassifier()\n",
    "clf.fit(X_train, y_train)\n",
    "y_pred_train = clf.predict(X_train)\n",
    "y_pred_test = clf.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_evaluation(X_train, X_test, y_train, y_test, y_pred_train, y_pred_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "roc_curve_and_auc(clf, X_train, X_test, y_train, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf.feature_importances_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_feature_importances(clf)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Feature Importance\n",
    "Class Weight\n",
    "Over Under SAmpling SMOTE yaptim\n",
    "Stratify\n",
    "Radius Neighbors Classifier Cok fazla model oldu\n",
    "bagging yaptim\n",
    "make_scorer\n",
    "\n",
    "simple imputer\n",
    "n_jobs = -1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "cohen_kappa_score\n",
    "Cohen suggested the Kappa result be interpreted as follows: values ≤ 0 as indicating no agreement and 0.01–0.20 as none to slight, 0.21–0.40 as fair, 0.41– 0.60 as moderate, 0.61–0.80 as substantial, and 0.81–1.00 as almost perfect agreement."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "https://www.kaggle.com/stuarthallows/using-xgboost-with-scikit-learn"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
